---
layout: post_mine
title:  machine learning
---

K-Means

说收敛慢的那个注意下kmeans业界用得多的原因之一就是收敛快，现在还能通过分布式计算加速，别的原因有调参就一个K。
缺点大把，其实聚类这种non-supervised 的东西一只被人们诟病。

- 调K。虽然只用调一个参数，但是clustering的几个metrics，gap statistic，silhouette statistic，算起来都很慢，很慢很慢。
- Kmeans 其实是在做convex optimization ，遇到non-convex 的distribution 就挂了。怎么办？加Kernel 。加什么Kernel 慢慢试吧，svm用什么Kernel好不就是这一个个试出来的嘛。
- 不怎么robust ，所以就出现KMedians,KMedoid 这种更慢的东西。
- Hidden class highly imbalanced 的时候效果不好。这个自己造几个数据试试就知道了。
- 收敛到局部最优，类似EM。要算好多好多次~

参考:
- [1](https://www.zhihu.com/question/31296149)
- [https://zhuanlan.zhihu.com/p/20432322](https://zhuanlan.zhihu.com/p/20432322) 
- [https://zhuanlan.zhihu.com/p/20445085](https://zhuanlan.zhihu.com/p/20445085)
- [99%](http://blog.csdn.net/v_july_v/article/details/7382693)
- [常见面试之机器学习算法思想简单梳理](http://www.cnblogs.com/tornadomeet/p/3395593.html)
- [分类回归树CART](http://www.cnblogs.com/zhangchaoyang/articles/2709922.html)

- SVM的原理，SVM里面的核
- K-means，如何用hadoop实现k-means
- naive bayes和logistic regression的区别
- LDA的原理和推导
- 做广告点击率预测，用哪些数据什么算法
- 推荐系统的算法中最近邻和矩阵分解各自适用场景
- 用户流失率预测怎么做（游戏公司的数据挖掘都喜欢问这个）
- 一个游戏的设计过程中该收集什么数据
- 如何从登陆日志中挖掘尽可能多的信息

- KNN（分类与回归）
- CART（回归树用平方误差最小化准则，分类树用基尼指数最小化准则）
[http://dataunion.org/5771.html](http://dataunion.org/5771.html)
当数据拥有众多特征并且特征之间关系十分复杂时，构建全局模型的想法就显得太难了，也略显笨拙。而且，实际生活中很多问题都是非线性的，不可能使用全局线性模型来拟合任何数据。一种可行的方法是将数据集切分成很多份易建模的数据，然后利用线性回归技术来建模。如果首次切分后仍然难以拟合线性模型就继续切分。在这种切分方式下，树结构和回归法就相当有用。
回归树与分类树的思路类似，但叶节点的数据类型不是离散型，而是连续型，对CART稍作修改就可以处理回归问题。CART算法用于回归时根据叶子是具体指还是另外的机器学习模型又可以分为回归树和模型树。但无论是回归树还是模型树，其适用场景都是：标签值是连续分布的，但又是可以划分群落的，群落之间是有比较鲜明的区别的，即每个群落内部是相似的连续分布，群落之间分布确是不同的。所以回归树和模型树既算回归，也称得上分类。
回归是为了处理预测值是连续分布的情景，其返回值应该是一个具体预测值。回归树的叶子是一个个具体的值，从预测值连续这个意义上严格来说，回归树不能称之为“回归算法”。因为回归树返回的是“一团”数据的均值，而不是具体的、连续的预测值（即训练数据的标签值虽然是连续的，但回归树的预测值却只能是离散的）。所以回归树其实也可以算为“分类”算法，其适用场景要具备“物以类聚”的特点，即特征值的组合会使标签属于某一个“群落”，群落之间会有相对鲜明的“鸿沟”。如人的风格是一个连续分布，但是却又能“群分”成文艺、普通和2B三个群落，利用回归树可以判断一个人是文艺还是2B，但却不能度量其有多文艺或者多2B。所以，利用回归树可以将复杂的训练数据划分成一个个相对简单的群落，群落上可以再利用别的机器学习模型再学习。 
模型树的叶子是一个个机器学习模型，如线性回归模型，所以更称的上是“回归”算法。利用模型树就可以度量一个人的文艺值了。

- Logistics（推导）
- GBDT（利用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值，拟合一个回归树）
- 随机森林（Bagging+CART）
- SVM与随机森林比较
- 改变随机森林的训练样本数据量，是否会影响到随机森林学习到的模型的复杂度
- Logistics与随机森林比较
- GBDT与随机森林比较
- 自己实现过什么机器学习算法
- 推荐算法（基于用户的协同过滤，基于内容的协同过滤）
- 如何做一个新闻推荐

- 项目的特征向量的归一化与异常处理
- 线性分类器与非线性分类器的区别及优劣；
- 特征比数据量还大时，选择什么样的分类器？
- 对于维度很高的特征，你是选择线性还是非线性分类器？
- 对于维度极低的特征，你是选择线性还是非线性分类器？
- 如何解决过拟合问题？
- L1和L2正则的区别，如何选择L1和L2正则？
- 随机森林的学习过程；
- 随机森林中的每一棵树是如何学习的；
- 随机森林学习算法中CART树的基尼指数是什么？

- 如果有背景，item和cf协同过滤的优缺点，如何从计算公式证明，各种情况的惩罚，hadoop上mr的实现，包括各种情况的惩罚。
- 线性回归的梯度下降和牛顿法求解公式的推导
- 贝叶斯分类器的优化和特殊情况的处理
- 决策树的的训练……

- 实现一个分布式的矩阵向量乘的算法。。。
好吧 这个我学过 blabla讲了一堆 也不知道对不对 
- 最速下降法和共轭梯度法 wolfe条件 最速下降法和共轭梯度法的收敛速度如何判断。。。
两种方法的概念答上来了 wolfe条件没准备到 收敛速度大概回答了一下 我印象中只记得共轭梯度的误差估计了 
- 约束优化的KKT条件 KKT条件在边界区域的搜索行为的物理意义是什么。。。
KKT条件ok 物理意义没答上来 
- 实现一个分布式的topN算法。。。
topN看过 不过分布式嘛。。。 就是追着你问 问到你不会为止
- 为什么可以使用logistic回归。。。
这个我不懂。。。 好吧 hr让我去看看《离散选择方法》这本书。。。 算是学到了
- 你了解的机器学习算法有哪些。。。
这个简单。。。
- 选一个你熟悉的算法 详细推导公式过程。。。
推公式我在行 不过hr貌似不感冒 
- 一个实际应用的问题 因为没有背景 所以只好放弃

https://www.zhihu.com/question/23259302/answer/24857674
机器学习方面的面试主要分成三个部分： 1. 算法和理论基础 2. 工程实现能力与编码水平 3. 业务理解和思考深度 

1. 理论方面，我推荐最经典的一本书《统计学习方法》，这书可能不是最全的，但是讲得最精髓，薄薄一本，适合面试前突击准备。 我认为一些要点是： 统计学习的核心步骤：模型、策略、算法，你应当对logistic、SVM、决策树、KNN及各种聚类方法有深刻的理解。能够随手写出这些算法的核心递归步的伪代码以及他们优化的函数表达式和对偶问题形式。 非统计学习我不太懂，做过复杂网络，但是这个比较深，面试可能很难考到。 数学知识方面，你应当深刻理解矩阵的各种变换，尤其是特征值相关的知识。 算法方面：你应当深刻理解常用的优化方法：梯度下降、牛顿法、各种随机搜索算法（基因、蚁群等等），深刻理解的意思是你要知道梯度下降是用平面来逼近局部，牛顿法是用曲面逼近局部等等。 

2. 工程实现能力与编码水平 机器学习从工程实现一般来讲都是某种数据结构上的搜索问题。 你应当深刻理解在1中列出的各种算法对应应该采用的数据结构和对应的搜索方法。比如KNN对应的KD树、如何给图结构设计数据结构？如何将算法map-red化等等。 一般来说要么你会写C，而且会用MPI，要么你懂Hadoop，工程上基本都是在这两个平台实现。实在不济你也学个python吧。 

3. 非常令人失望地告诉你尽管机器学习主要会考察1和2 但是实际工作中，算法的先进性对真正业务结果的影响，大概不到30%。当然算法必须要足够快，离线算法最好能在4小时内完成，实时算法我没搞过，要求大概更高。 机器学习大多数场景是搜索、广告、垃圾过滤、安全、推荐系统等等。对业务有深刻的理解对你做出来的系统的结果影响超过70%。这里你没做过实际的项目，是完全不可能有任何体会的，我做过一个推荐系统，没有什么算法上的高大上的改进，主要是业务逻辑的创新，直接就提高了很明显的一个CTR（具体数目不太方便透露，总之很明显就是了）。如果你做过实际的项目，一定要主动说出来，主动让面试官知道，这才是最大最大的加分项目。 最后举个例子，阿里内部机器学习挑战赛，无数碾压答主10000倍的大神参赛。最后冠军没有用任何高大上的算法而是基于对数据和业务的深刻理解和极其细致的特征调优利用非常基本的一个算法夺冠。所以啥都不如真正的实操撸几个生产项目啊。


我面的推荐，问了各类协同过滤的好与坏。
然后我说我做过LDA，问我，Dirichlet Distribution的定义和性质，并问我，为什么它和multinomial distribution是共轭的，顺便问了我啥叫共轭分布。
问了一个很有意思的问题，现实应用中的Top-N推荐问题和学术研究中的评分预测问题之间有什么不同。
问我ItemCF的工程实现，面对大数据如何实现，又追问了有没有什么工程优化算法。这个问题我没答好，一开始我说了一个MapReduce模型，他问能不能更快一点，我就卡那了。。。最后面试官告诉我，不能只从算法角度分析，要从系统设计分析，利用内存来减小MapReduce的吞吐量。（当然也许从MapReduce那一刻开始我就输了也不一定）
最后考了我一个基本概念，什么叫判别模型什么叫生成模型。
